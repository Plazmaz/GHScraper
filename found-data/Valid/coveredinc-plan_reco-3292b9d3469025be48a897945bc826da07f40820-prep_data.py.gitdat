import argparse
import json
import psycopg2
import psycopg2.extras
import pandas as pd
import numpy as np
import scipy as sp
from scipy import sparse
from tqdm import tqdm
from sklearn import preprocessing
import patsy
try:
    import cPickle as pickle
except ImportError:
    import pickle


def extract_features(app, app_addl_info):
    user_features = extract_user_features(app)
    app_id = user_features.get('app_id')

    rec = app_addl_info.get(app_id)

    if rec is not None:
        keynames = ['plan_premium_month', 'subsidy', 'plan_id']
        for kname in keynames:
            if rec[kname] is not None:
                if [kname] == 'plan_id':
                    rec[kname] = int(rec[kname])
                else:
                    rec[kname] = float(rec[kname])
        user_features.update(rec)

        fullplan_list = [
            extract_plan_features(plan, user_features['family_size'])
            for plan in app['payload']['merged']]

        return dict(userFeatures=user_features,
                    fullPlanList=fullplan_list)


def extract_user_features(app):
    email = app['email']
    user_id = app['userId']
    app_id = app['appId']

    mods = app['payload']['merged'][0]['mods']

    ndrugs = len(mods['userDrugs'])

    providers = mods['providers']
    n_prvdrs_added = len(providers['providersAccepted'])

    return dict(email=email,
                userId=user_id,
                app_id=app_id,
                ndrugs=ndrugs,
                nPrvdrsAdded=n_prvdrs_added)


def extract_plan_features(planjson, fam_size):
    if planjson is None:
        return None

    mods = planjson.get('mods')
    providers = mods['providers']
    n_prvdrs_accepted = providers['totalAccepted']
    n_prvdrs_nearby = providers['qtyNearby']

    if fam_size == 1:
        deductible = planjson.get(
            'deductibleInd') if 'deductibleInd' in planjson else 0
        oopmax = planjson.get('oopmaxInd') if 'oopmaxInd' in planjson else 0
    else:
        deductible = planjson.get(
            'deductibleFam') if 'deductibleFam' in planjson else planjson.get(
            'deductibleInd')
        oopmax = planjson.get(
            'oopmaxFam') if 'oopmaxFam' in planjson else planjson.get(
            'oopmaxInd')

    ret = dict(deductible=deductible,
               oopmax=oopmax,
               carrier=planjson.get('carrier'),
               metalType=planjson.get('metalType'),
               planType=planjson.get('planType'),
               nPrvdrsAccepted=n_prvdrs_accepted,
               nPrvdrsNearby=n_prvdrs_nearby,
               allInForecast=mods.get('allInForecast'),
               premium=mods.get('premium'),
               premiumMonth=mods.get('premiumMonth'),
               premiumYear=mods.get('premiumYear'),
               planID=mods.get('planId'),
               planName=planjson.get('name'),
               strideRank=mods.get('ranks')['strideRank'])

    return ret


def read_app_ids(name):
    '''
    Red through the JSON file and yield only the application IDs (appId)

    Args:
        name (str): Path of file containing the relevant apps.

    Yields:
        (str) application IDs

    '''
    with open(flnm, 'r') as f:
        for line in f:
            onejson = json.loads(line)
            yield onejson['appId']


def purchased_app_ids():

    con = psycopg2.connect(database='purchaseapps',
                           host='localhost',
                           port='5432')
    cur = con.cursor()
    cur.execute("SELECT app_id FROM purchases;")

    all_app_ids = [x[0] for x in cur.fetchall()]

    cur.close()
    con.close()
    return all_app_ids


def get_additional_user_info(all_app_ids):
    conn = psycopg2.connect(database='stride_bi',
                            user='stride_analyst',
                            password='ve5ekFS8zRKAybGM9oGw',
                            host='bi.cgv2wqpzi494.us-west-2.rds.amazonaws.com',
                            port='5432')
    cur = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)

    cur.execute("""SELECT app_id, plan_id, num_lives, family_size, subsidy,
                   plan_premium_month, plan_csr
                   FROM app_view WHERE app_id = ANY(%s);""",
                (all_app_ids,))
    rec = cur.fetchall()
    app_addl_info = {app['app_id']: dict(app) for app in rec}
    cur.close()
    conn.close()
    return app_addl_info


def read_plan_recomendations(name, app_addl_info=None):
    app_addl_info = app_addl_info or get_additional_user_info(
        purchased_app_ids())
    with open(name, 'r') as f:
        print('BUILDING DATA FROM JSON FILE...')
        for line in f:
            onejson = json.loads(line)
            yield extract_features(onejson, app_addl_info)


def build_from_json_file(name):
    return read_plan_recomendations(name)


def json_to_pickle(jname, pname):
    data = list(build_from_json_file(jname))
    with open(pname, 'w+') as f:
        print('DUMPING DATA TO PICKLE FILE...')
        pickle.dump(data, f)
    return data


def build_from_pickle_file(pname):
    with open(pname, 'r') as f:
        print('BUILDING DATA FROM PICKLE FILE...')
        return pickle.load(f)


def tempfn(data, create_rank_vars=True,
           scale_plan_data=False, scale_user_data=False, verbose=False):

    for obj in data:
        for plan in obj['fullPlanList']:
            plan['app_id'] = obj['userFeatures']['app_id']

    # basically just flattening a list of lists
    stacked_data = [item for sublist in [x['fullPlanList'] for x in data] for
                    item in sublist]

    user_data = pd.DataFrame([item['userFeatures'] for item in data])
    plan_data = pd.DataFrame(stacked_data)

    # Make sure plan IDs in both DataFrames are of equivalent types
    user_data['plan_id'] = user_data['plan_id'].astype(np.int64)
    plan_data['planID'] = plan_data['planID'].astype(np.int64)

    # Drop unnecessary columns
    plan_data = plan_data[
        ['app_id', 'planName', 'carrier', 'planType', 'planID', 'metalType',
         'strideRank', 'allInForecast',
         'deductible', 'nPrvdrsAccepted', 'nPrvdrsNearby',
         'oopmax', 'premiumMonth', 'premium', 'premiumYear']]

    # Make some changes to user data
    user_data.rename(index=str, columns={"plan_id": "purchased_planID"},
                     inplace=True)
    user_data['zeroPrvdrsAdded'] = 1 * (user_data['nPrvdrsAdded'] == 0)
    user_data['subsidy'].fillna(0, inplace=True)

    plan_data['zeroPrvdrsNearby'] = 1 * (plan_data['nPrvdrsNearby'] == 0)

    plan_data_numerics = ['allInForecast', 'deductible', 'nPrvdrsAccepted',
                          'nPrvdrsNearby', 'oopmax', 'premiumMonth',
                          'premium', 'premiumYear']

    if create_rank_vars:
        if verbose:
            print('creating ranked verson of numeric variables...')

        # For each app_id group, calculate the rank of the plan according to a
        # variety of variables
        plan_data_grpd = plan_data.groupby('app_id')

        for numvar in plan_data_numerics:
            plan_data[numvar + '_rank'] = plan_data_grpd.apply(
                lambda x: x[numvar].rank(method='dense')).reset_index(level=0,
                                                                      drop=True)
        plan_data_numerics.extend([x + '_rank' for x in plan_data_numerics])

    scaler = preprocessing.MinMaxScaler()

    if scale_plan_data:
        if verbose:
            print('scaling plan data...')

        plan_data_grpd = plan_data.groupby('app_id')

        def scale_numeric_columns(grp):
            grp.loc[:, plan_data_numerics] = scaler.fit_transform(
                grp[plan_data_numerics])
            return grp

        plan_data = plan_data_grpd.apply(scale_numeric_columns)

    if scale_user_data:
        if verbose:
            print('scaling user data...')
        user_data_numerics = ['num_lives', 'nPrvdrsAdded', 'ndrugs', 'subsidy']
        user_data.loc[:, user_data_numerics] = scaler.fit_transform(
            user_data[user_data_numerics])

    if verbose:
        print('merging plan and user data together...')
    merged_data = plan_data.merge(user_data, how='inner', on='app_id')

    merged_data['pctPrvdrsAccepted'] = merged_data['nPrvdrsAccepted'] / \
                                       merged_data['nPrvdrsAdded']
    merged_data['pctPrvdrsAccepted'].fillna(0, inplace=True)

    merged_data['labels'] = 1 * (
        merged_data['purchased_planID'] == merged_data['planID'])

    # For some reason there are some purchases where the listed purchased plan
    # ID does not match any of the plan IDs that
    merged_data = merged_data.groupby('app_id').filter(
        lambda x: x['labels'].sum() == 1)

    return merged_data


if __name__ == '__main__':

    parser = argparse.ArgumentParser(description='''Compile health plan
        purchase data from a variety of sources for learning purposes.''')

    parser.add_argument('-jf', '--jsonfile', help='path of the JSON file')
    parser.add_argument('-pf', '--picklefile', help='path of the pickle file')
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='print progress to sys.stdout')
    parser.add_argument('-rk', '--rank', action='store_true',
                        help='''should ranked version of numeric variables be
                                created?''')
    parser.add_argument('-sp', '--scaleplanvars', action='store_true',
                        help='''should we scale plan features? each numeric
                                feature for each app_id will be scaled to have
                                min 0 and max 1''')
    parser.add_argument('-su', '--scaleuservars', action='store_true',
                        help='''should we scale user features? each numeric
                                feature for will be scaled to have
                                min 0 and max 1''')
    parser.add_argument('-t', '--buildtype', choices=['JSON', 'pickle'],
                        required=True,
                        help='''Build data from JSON file or pickle file? Pickle
                                file implies that we've already built from JSON
                                file once before.''')
    parser.add_argument('-pd', '--pandasfile', required=True,
                        help='''path of where to dump pandas.DataFrame''')

    args = parser.parse_args()
    print args

    if args.buildtype == 'JSON':
        if not args.jsonfile or not args.picklefile:
            msg = '''If build flag is set to True then user must provide
                     JSONFILE and PICKLEFILE'''
            raise argparse.ArgumentTypeError(msg)

        data = json_to_pickle(args.jsonfile, args.picklefile)

    if args.buildtype == 'pickle':
        if not args.picklefile:
            msg = 'If build flag is set to False then user must provide' \
                  'PICKLEFILE'
            raise argparse.ArgumentTypeError(msg)
        elif args.jsonfile:
            msg = '''WARNING: when building data from PICKLEFILE, providing
                     JSONFILE is not necessary. JSONFILE argument is being
                     ignored.'''
            raise argparse.ArgumentTypeError(msg)

        data = build_from_pickle_file(args.picklefile)

    data = tempfn(data,
                  scale_plan_data=args.scaleplanvars,
                  scale_user_data=args.scaleuservars,
                  create_rank_vars=args.rank,
                  verbose=args.verbose)

    data.to_csv(args.pandasfile)

    if args.verbose:
        print('DONE.')
    print(data.shape)

